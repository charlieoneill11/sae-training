{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11bad86350c498895cf32c68c74bdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting questions into text (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"openlifescienceai/medmcqa\", split=\"train\", streaming=False)\n",
    "\n",
    "rows_to_keep = 10_000\n",
    "\n",
    "# Only keep the first 10,000 rows\n",
    "ds = ds.select(range(rows_to_keep))\n",
    "\n",
    "def format_question_text(example):\n",
    "    \"\"\"\n",
    "    Transforms a dataset example into a formatted text string.\n",
    "    Args:\n",
    "        example: Dictionary containing the question data with keys:\n",
    "                'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'exp'\n",
    "    Returns:\n",
    "        Dict with new 'text' key containing formatted string\n",
    "    \"\"\"\n",
    "    # Option keys in order\n",
    "    option_keys = ['opa', 'opb', 'opc', 'opd']\n",
    "\n",
    "    # Build the formatted string components\n",
    "    question = f\"{example['question']}\"\n",
    "    # Strip ':' from the end of the question\n",
    "    question = question.rstrip(':')\n",
    "    # Add a period to the end of the question\n",
    "    question = question + '?'\n",
    "    options = \"\\nThe options are:\\n\" + \"\\n\".join(example[key] for key in option_keys)\n",
    "\n",
    "    # Get correct option using the cop index\n",
    "    correct_idx = int(example['cop'])\n",
    "    correct_option = f\"\\nCorrect option: {example[option_keys[correct_idx]]}\"\n",
    "\n",
    "    # Add explanation if available\n",
    "    explanation = f\"\\nExplanation: {example['exp']}\" if 'exp' in example else \"\"\n",
    "    # Strip anything after and including 'Ref'\n",
    "    explanation = explanation.split('Ref')[0]\n",
    "\n",
    "    # Combine all components\n",
    "    formatted_text = f\"{question}{options}{correct_option}{explanation}\"\n",
    "\n",
    "    # Return dictionary with new text field\n",
    "    example['text'] = formatted_text\n",
    "    return example\n",
    "\n",
    "# Function to transform the entire dataset\n",
    "def transform_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Applies the formatting transformation to the entire dataset.\n",
    "    Args:\n",
    "        dataset: Huggingface dataset object\n",
    "    Returns:\n",
    "        Transformed dataset with new 'text' column\n",
    "    \"\"\"\n",
    "    return dataset.map(\n",
    "        format_question_text,\n",
    "        desc=\"Formatting questions into text\",\n",
    "        num_proc=4  # Adjust based on your system\n",
    "    )\n",
    "\n",
    "transformed_ds = transform_dataset(ds)\n",
    "transformed_ds.to_pandas()\n",
    "# Drop all columns except text\n",
    "transformed_ds = transformed_ds.remove_columns([col for col in transformed_ds.column_names if col != 'text'])\n",
    "transformed_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/cdt_cw_5265_z_gwnxlf0tv80000gn/T/ipykernel_85048/2113412534.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  activations = torch.load(activation_file)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Define the SAE model\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "        # Dimensions\n",
    "        self.d_model = d_model\n",
    "        self.d_sae = d_sae\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "\n",
    "width='16k'\n",
    "l0 = 71\n",
    "layer = 20\n",
    "\n",
    "# Load the SAE model\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=\"google/gemma-scope-2b-pt-res\",\n",
    "    filename=f\"layer_{layer}/width_{width}/average_l0_{l0}/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).cpu() for k, v in params.items()}\n",
    "\n",
    "# Initialize and load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.cpu()\n",
    "\n",
    "# Load your data from Hugging Face\n",
    "repo_id = \"charlieoneill/gemma-medicine-sae\"  # Replace with your repo\n",
    "\n",
    "# Download the activation tensor and dataset\n",
    "api = HfApi()\n",
    "activation_file = hf_hub_download(repo_id=repo_id, filename=\"10000_128.pt\")\n",
    "\n",
    "# Load the tensors\n",
    "activations = torch.load(activation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 128, 2304])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.d_sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained: 0.8750\n",
      "L0 sparsity: 0.0043\n"
     ]
    }
   ],
   "source": [
    "# Move to GPU\n",
    "activations = activations.cpu()\n",
    "\n",
    "# Process a batch of 32\n",
    "# batch_size = 1\n",
    "# batch_acts = activations[:batch_size]\n",
    "batch_acts = activations[4].unsqueeze(0)\n",
    "\n",
    "# Run through SAE\n",
    "with torch.no_grad():\n",
    "    recon = sae(batch_acts)\n",
    "\n",
    "# Calculate variance explained\n",
    "variance_explained = 1 - torch.mean((recon[:, 1:] - batch_acts[:, 1:].to(torch.float32)) **2) / (batch_acts[:, 1:].to(torch.float32).var())\n",
    "\n",
    "# Calculate L0 sparsity\n",
    "with torch.no_grad():\n",
    "    encoded = sae.encode(batch_acts)\n",
    "    l0_sparsity = (encoded > 0).float().mean()\n",
    "\n",
    "print(f\"Variance explained: {variance_explained.item():.4f}\")\n",
    "print(f\"L0 sparsity: {l0_sparsity.item():.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 128, 2304])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 2304])\n",
      "torch.Size([1, 128, 65536]) torch.Size([1, 128, 2304])\n"
     ]
    }
   ],
   "source": [
    "target_act = activations[4].unsqueeze(0)\n",
    "print(target_act.shape)\n",
    "\n",
    "sae_acts = sae.encode(target_act.to(torch.float32))\n",
    "recon = sae.decode(sae_acts)\n",
    "\n",
    "print(sae_acts.shape, recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.0132, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print MSE loss between target_act and recon\n",
    "loss = torch.mean((recon[:, 1:] - target_act[:, 1:].to(torch.float32)) **2)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8750, grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - torch.mean((recon[:, 1:] - target_act[:, 1:].to(torch.float32)) **2) / (target_act[:, 1:].to(torch.float32).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27429,    50,    66,    61,    66,    77,    74,    73,    74,    44,\n",
       "            49,    50,    62,    56,    64,    45,    68,    77,    63,    59,\n",
       "            46,    52,    52,    57,    62,    75,    60,    59,    56,    72,\n",
       "            70,    67,    48,    82,    83,    49,    59,    53,    63,    54,\n",
       "            52,    90,    63,    46,    51,    60,    38,    52,    82,    39,\n",
       "            39,    46,    60,    67,    62,    49,    52,    68,    75,    63,\n",
       "            66,    68,    69,    38,    65,    82,    71,    69,    84,    58,\n",
       "            60,    77,    79,    64,    52,    65,    79,    63,    77,    56,\n",
       "            78,    66,    76,    81,    68,    73,    80,    54,    56,    88,\n",
       "            58,    70,    67,    59,    68,    67,    70,    70,    75,    52,\n",
       "            81,    69,    88,    73,    63,    79,    62,    36,    76,    76,\n",
       "            68,    75,    76,    70,    77,    91,    89,    92,    50,    77,\n",
       "            73,    95,    63,    77,    59,    56,    68,    55]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sae_acts > 1).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 75, Feature 19451: Activation 160.45\n",
      "Position 28, Feature 38187: Activation 151.08\n",
      "Position 1, Feature 19802: Activation 129.82\n",
      "Position 3, Feature 62431: Activation 128.68\n",
      "Position 49, Feature 48639: Activation 126.09\n",
      "Position 16, Feature 52421: Activation 125.92\n",
      "Position 127, Feature 44592: Activation 122.17\n",
      "Position 109, Feature 31548: Activation 118.08\n",
      "Position 95, Feature 53551: Activation 117.55\n",
      "Position 104, Feature 44466: Activation 116.45\n"
     ]
    }
   ],
   "source": [
    "# values, inds = sae_acts.max(-1)\n",
    "\n",
    "# inds, inds.shape\n",
    "\n",
    "# First flatten the sequence dimension, but exclude first position\n",
    "flat_acts = sae_acts[:, 1:, :].reshape(sae_acts.shape[0], -1)  # Note the 1: slice\n",
    "\n",
    "# Get top 10 values and indices\n",
    "top_values, top_indices = torch.topk(flat_acts, k=10, dim=-1)\n",
    "\n",
    "# Convert flat indices back to (seq_pos, feature) pairs\n",
    "# Add 1 to seq_pos since we excluded the first position\n",
    "seq_pos = (top_indices // sae_acts.shape[-1]) + 1  # add 1 to account for skipped first position\n",
    "feature_ids = top_indices % sae_acts.shape[-1]\n",
    "\n",
    "# Print results\n",
    "for i in range(10):\n",
    "    print(f\"Position {seq_pos[0][i]}, Feature {feature_ids[0][i]}: Activation {top_values[0][i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growth hormone has its effect on growth through??\n",
      "The options are:\n",
      "Directly\n",
      "IG1-1\n",
      "Thyroxine\n",
      "Intranuclear receptors\n",
      "Correct option: IG1-1\n",
      "Explanation: Ans. is 'b' i.e., IGI-1GH has two major functions :-i) Growth of skeletal system :- The growth is mediated by somatomedins (IGF). Increased deposition of cailage (including chondroitin sulfate) and bone with increased proliferation of chondrocytes and osteocytes.ii) Metabolic effects :- Most of the metabolic effects are due to direct action of GH. These include gluconeogenesis, decreased peripheral utilization of glucose (decreased uptake), lipolysis and anabolic effect on proteins.\n"
     ]
    }
   ],
   "source": [
    "print(transformed_ds[4]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-65k/19451?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x3430bb650>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "def get_dashboard_html(sae_release = \"gemma-2-2b\", sae_id=f\"{layer}-gemmascope-res-{width}\", feature_idx=0):\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "\n",
    "html = get_dashboard_html(sae_release = \"gemma-2-2b\", sae_id=f\"{layer}-gemmascope-res-{width}\", feature_idx=19451)\n",
    "IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#url = \"https://www.neuronpedia.org/api/explanation/export?modelId=gpt2-small&saeId=7-res-jb\"\n",
    "url = f\"https://www.neuronpedia.org/api/explanation/export?modelId=gemma-2-2b&saeId={layer}-gemmascope-res-{width}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>layer</th>\n",
       "      <th>feature</th>\n",
       "      <th>description</th>\n",
       "      <th>explanationModelName</th>\n",
       "      <th>typeName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>20-gemmascope-res-65k</td>\n",
       "      <td>1863</td>\n",
       "      <td>sentence beginnings</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>20-gemmascope-res-65k</td>\n",
       "      <td>2109</td>\n",
       "      <td>the conjunction \"and\"</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>20-gemmascope-res-65k</td>\n",
       "      <td>2634</td>\n",
       "      <td>the name \"ja rule.\"</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>20-gemmascope-res-65k</td>\n",
       "      <td>3339</td>\n",
       "      <td>references to pakistan</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>20-gemmascope-res-65k</td>\n",
       "      <td>3408</td>\n",
       "      <td>mentions of the name \"nick.\"</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74649</th>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>20-gemmascope-res-65k</td>\n",
       "      <td>52527</td>\n",
       "      <td>references to obstacles or challenges</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74650</th>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>20-gemmascope-res-65k</td>\n",
       "      <td>40585</td>\n",
       "      <td>references to configuration options</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74651</th>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>20-gemmascope-res-65k</td>\n",
       "      <td>53745</td>\n",
       "      <td>the term \"broad\" in various contexts</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74652</th>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>20-gemmascope-res-65k</td>\n",
       "      <td>53808</td>\n",
       "      <td>java import statements in code</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74653</th>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>20-gemmascope-res-65k</td>\n",
       "      <td>27611</td>\n",
       "      <td>prepositions indicating locations or times</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>oai_token-act-pair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74654 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          modelId                  layer feature  \\\n",
       "0      gemma-2-2b  20-gemmascope-res-65k    1863   \n",
       "1      gemma-2-2b  20-gemmascope-res-65k    2109   \n",
       "2      gemma-2-2b  20-gemmascope-res-65k    2634   \n",
       "3      gemma-2-2b  20-gemmascope-res-65k    3339   \n",
       "4      gemma-2-2b  20-gemmascope-res-65k    3408   \n",
       "...           ...                    ...     ...   \n",
       "74649  gemma-2-2b  20-gemmascope-res-65k   52527   \n",
       "74650  gemma-2-2b  20-gemmascope-res-65k   40585   \n",
       "74651  gemma-2-2b  20-gemmascope-res-65k   53745   \n",
       "74652  gemma-2-2b  20-gemmascope-res-65k   53808   \n",
       "74653  gemma-2-2b  20-gemmascope-res-65k   27611   \n",
       "\n",
       "                                       description explanationModelName  \\\n",
       "0                              sentence beginnings          gpt-4o-mini   \n",
       "1                            the conjunction \"and\"          gpt-4o-mini   \n",
       "2                              the name \"ja rule.\"          gpt-4o-mini   \n",
       "3                           references to pakistan          gpt-4o-mini   \n",
       "4                     mentions of the name \"nick.\"          gpt-4o-mini   \n",
       "...                                            ...                  ...   \n",
       "74649        references to obstacles or challenges          gpt-4o-mini   \n",
       "74650          references to configuration options          gpt-4o-mini   \n",
       "74651         the term \"broad\" in various contexts          gpt-4o-mini   \n",
       "74652               java import statements in code          gpt-4o-mini   \n",
       "74653   prepositions indicating locations or times          gpt-4o-mini   \n",
       "\n",
       "                 typeName  \n",
       "0      oai_token-act-pair  \n",
       "1      oai_token-act-pair  \n",
       "2      oai_token-act-pair  \n",
       "3      oai_token-act-pair  \n",
       "4      oai_token-act-pair  \n",
       "...                   ...  \n",
       "74649  oai_token-act-pair  \n",
       "74650  oai_token-act-pair  \n",
       "74651  oai_token-act-pair  \n",
       "74652  oai_token-act-pair  \n",
       "74653  oai_token-act-pair  \n",
       "\n",
       "[74654 rows x 6 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert to pandas\n",
    "data = response.json()\n",
    "explanations_df = pd.DataFrame(data)\n",
    "# rename index to \"feature\"\n",
    "explanations_df.rename(columns={\"index\": \"feature\"}, inplace=True)\n",
    "# explanations_df[\"feature\"] = explanations_df[\"feature\"].astype(int)\n",
    "explanations_df[\"description\"] = explanations_df[\"description\"].apply(\n",
    "    lambda x: x.lower()\n",
    ")\n",
    "explanations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, feature_ids = sae_acts.max(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 16513:\n",
      "terms related to rankings or titles within a police or law enforcement context\n",
      "\n",
      "\n",
      "Feature 13699:\n",
      " references to medical terminology or conditions related to the brain or neurological structures\n",
      "\n",
      "\n",
      "Feature 19844:\n",
      "elements related to providing answers or explanations\n",
      "\n",
      "\n",
      "Feature 28167:\n",
      " page references and letter indications in a document\n",
      "\n",
      "\n",
      "Feature 43399:\n",
      "references to development or related code elements\n",
      "\n",
      "\n",
      "Feature 16521:\n",
      " financial terms related to bond markets and yields\n",
      "\n",
      "\n",
      "Feature 43786:\n",
      "references to leadership titles and positions within organizations\n",
      "\n",
      "\n",
      "Feature 40458:\n",
      " expressions of necessity and responsibility regarding educational policies and practices\n",
      "\n",
      "\n",
      "Feature 62226:\n",
      " punctuation marks and separate ideas or phrases\n",
      "\n",
      "\n",
      "Feature 55701:\n",
      " technical terms related to programming and data structures\n",
      "\n",
      "\n",
      "Feature 52632:\n",
      " elements related to user interface features and functionalities\n",
      "\n",
      "\n",
      "Feature 6296:\n",
      " instances of marking or signaling changes in sections of text\n",
      "\n",
      "\n",
      "Feature 12696:\n",
      "references to personal possession and specific locations or contexts related to individuals\n",
      "\n",
      "\n",
      "Feature 62234:\n",
      " references to individual costs associated with group activities or events\n",
      "\n",
      "\n",
      "Feature 61217:\n",
      " mentions of a specific place, la casa\n",
      "\n",
      "\n",
      "Feature 27556:\n",
      " occurrences of function definitions or methods in programming code\n",
      "\n",
      "\n",
      "Feature 20900:\n",
      " phrases related to legal terminology and constitutional issues\n",
      "\n",
      "\n",
      "Feature 50469:\n",
      "logical reasoning and argumentative constructs\n",
      "\n",
      "\n",
      "Feature 61350:\n",
      " technical terms related to javascript and just-in-time (jit) compilation\n",
      "\n",
      "\n",
      "Feature 24234:\n",
      " parentheses in code structures\n",
      "\n",
      "\n",
      "Feature 45867:\n",
      "references to support or funding for a project\n",
      "\n",
      "\n",
      "Feature 38187:\n",
      " references to physical body parts\n",
      "\n",
      "\n",
      "Feature 46637:\n",
      " forms of the verb \"appear.\"\n",
      "\n",
      "\n",
      "Feature 11820:\n",
      " references to accidents and collisions involving vehicles\n",
      "\n",
      "\n",
      "Feature 60847:\n",
      " words that indicate uncertainty or caution\n",
      "\n",
      "\n",
      "Feature 53551:\n",
      "references to a specific coffee place named \"brew.\"\n",
      "\n",
      "\n",
      "Feature 51245:\n",
      " keywords related to data partitioning in database contexts\n",
      "\n",
      "\n",
      "Feature 44466:\n",
      "elements related to legal decisions or formal rulings\n",
      "\n",
      "\n",
      "Feature 16179:\n",
      " the beginning of segments in a structured document format\n",
      "\n",
      "\n",
      "Feature 55220:\n",
      " mathematical notation and symbols used in formulas\n",
      "\n",
      "\n",
      "Feature 11061:\n",
      " temporal and logistical details concerning events\n",
      "\n",
      "\n",
      "Feature 28853:\n",
      "concepts related to economic disparity and fiscal policies\n",
      "\n",
      "\n",
      "Feature 59959:\n",
      " references to ethnicity or ethnic identity\n",
      "\n",
      "\n",
      "Feature 4536:\n",
      " references to concepts and definitions\n",
      "\n",
      "\n",
      "Feature 60344:\n",
      "terms related to osteoporosis and its diagnostic methods\n",
      "\n",
      "\n",
      "Feature 47993:\n",
      "references to desserts, specifically banana splits\n",
      "\n",
      "\n",
      "Feature 31548:\n",
      " indications of initialization and assignment in code contexts\n",
      "\n",
      "\n",
      "Feature 32062:\n",
      " occurrences of the word \"new,\" particularly in various contexts or formats\n",
      "\n",
      "\n",
      "Feature 42303:\n",
      " closing parentheses and the related syntax in programming constructs\n",
      "\n",
      "\n",
      "Feature 46272:\n",
      " mathematical symbols and notation related to equations or variables\n",
      "\n",
      "\n",
      "Feature 63679:\n",
      " phrases and terms related to online subscriptions and access to content\n",
      "\n",
      "\n",
      "Feature 52421:\n",
      " sql query components\n",
      "\n",
      "\n",
      "Feature 4552:\n",
      "names of universities and academic institutions\n",
      "\n",
      "\n",
      "Feature 1353:\n",
      "references to the term \"hunter\" and related discussions about hunting activities\n",
      "\n",
      "\n",
      "Feature 12232:\n",
      "key dates and names related to significant events or updates, particularly in political or scientific contexts\n",
      "\n",
      "\n",
      "Feature 27211:\n",
      " mathematical notation or symbols related to vectors and boldface representations\n",
      "\n",
      "\n",
      "Feature 39372:\n",
      " references to withdrawal or removal in various contexts\n",
      "\n",
      "\n",
      "Feature 60243:\n",
      "food-related terms that highlight cooking techniques and the appeal of fried foods\n",
      "\n",
      "\n",
      "Feature 19926:\n",
      "references to django forms and model integration in web development contexts\n",
      "\n",
      "\n",
      "Feature 19672:\n",
      "adjectives that describe characteristics or states\n",
      "\n",
      "\n",
      "Feature 19802:\n",
      " html and javascript elements pertaining to user interface controls, specifically related to checkbox inputs\n",
      "\n",
      "\n",
      "Feature 32252:\n",
      "references to completion or confirmation processes\n",
      "\n",
      "\n",
      "Feature 51292:\n",
      " moments of disbelief or disbelief in communication\n",
      "\n",
      "\n",
      "Feature 29151:\n",
      "references to physical impacts or injuries\n",
      "\n",
      "\n",
      "Feature 32608:\n",
      "database-related terms and identifiers\n",
      "\n",
      "\n",
      "Feature 62431:\n",
      " references to custom product manufacturing and demand\n",
      "\n",
      "\n",
      "Feature 6370:\n",
      "characters or symbols representative of data organization or coding\n",
      "\n",
      "\n",
      "Feature 44592:\n",
      " references to programming syntax and libraries\n",
      "\n",
      "\n",
      "Feature 23398:\n",
      " statistical analysis and results related to research studies\n",
      "\n",
      "\n",
      "Feature 40813:\n",
      " terms associated with lighting and illumination\n",
      "\n",
      "\n",
      "Feature 22893:\n",
      "repeated patterns or separators in visual or structured data formats\n",
      "\n",
      "\n",
      "Feature 10351:\n",
      " programming-related keywords associated with api requests and fields in code\n",
      "\n",
      "\n",
      "Feature 63218:\n",
      "terms related to coping mechanisms and psychological distress\n",
      "\n",
      "\n",
      "Feature 11635:\n",
      " lines of code that define or export functions and types\n",
      "\n",
      "\n",
      "Feature 46067:\n",
      " specifications related to width settings in a layout\n",
      "\n",
      "\n",
      "Feature 36724:\n",
      "references to age or year-related metrics\n",
      "\n",
      "\n",
      "Feature 36086:\n",
      "references to ownership and personal claims\n",
      "\n",
      "\n",
      "Feature 22648:\n",
      " instances of personal pronouns and references to people\n",
      "\n",
      "\n",
      "Feature 27897:\n",
      "legal terminology and references in case documents\n",
      "\n",
      "\n",
      "Feature 19451:\n",
      " references to opposition or resistance related to educational institutions and policies\n",
      "\n",
      "\n",
      "Feature 63100:\n",
      " terms related to android activity management and serialization\n",
      "\n",
      "\n",
      "Feature 14973:\n",
      "features related to email sending and contact management\n",
      "\n",
      "\n",
      "Feature 48639:\n",
      " references to family relationships and personal memories\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activating_features = list(set(feature_ids[0].cpu().numpy()))\n",
    "\n",
    "# Get the explanations for these features\n",
    "explanations_df.loc[activating_features]\n",
    "\n",
    "# Print the feature and explanation, one by one\n",
    "for feature in activating_features:\n",
    "    print(f\"Feature {feature}:\")\n",
    "    print(explanations_df.loc[feature][\"description\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the dashboard for this feature.\n",
    "html = get_dashboard_html(\n",
    "    sae_release=\"gpt2-small\",\n",
    "    sae_id=\"7-res-jb\",\n",
    "    feature_idx=bible_features.feature.values[0],\n",
    ")\n",
    "IFrame(html, width=1200, height=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
