{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import torch\n",
    "from jumprelu_sae import JumpReLUSAE  # Make sure jumprelu_sae.py is in your PYTHONPATH or same directory\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import hf_hub_download\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Automatically select between CUDA and CPU.\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load the activations.\n",
    "    # (Assumes a file 'activations.pt' containing a tensor of shape [10000, 128, 2304])\n",
    "    try:\n",
    "        # Load your data from Hugging Face\n",
    "        repo_id = \"charlieoneill/gemma-medicine-sae\"  # Replace with your repo\n",
    "\n",
    "        # Download the activation tensor and dataset\n",
    "        api = HfApi()\n",
    "        activation_file = hf_hub_download(repo_id=repo_id, filename=\"10000_128.pt\")\n",
    "\n",
    "        # Load the tensors\n",
    "        activations = torch.load(activation_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading activations: {e}\")\n",
    "        return\n",
    "\n",
    "    # Instantiate the SAE.\n",
    "    # Use the last dimension of activations as d_model, and choose a latent dimension (d_sae).\n",
    "    d_model = activations.shape[-1]  # e.g. 2304\n",
    "    d_sae = 65536  # Example latent dimension; adjust as needed.\n",
    "    sae = JumpReLUSAE(d_model=d_model, d_sae=d_sae, sparsity_coeff=0.1)\n",
    "    sae.to(device)\n",
    "\n",
    "    # Define training hyperparameters.\n",
    "    batch_size = 16384     # Mini-batch size (each token is treated as a separate example)\n",
    "    steps = 10_000        # Total training steps\n",
    "    log_freq = 100        # How often to log training statistics\n",
    "    lr = 1e-3             # Base learning rate\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    # Train the model on the activations.\n",
    "    # The optimize_on_activations method expects a tensor of shape (N, seq_len, d_model)\n",
    "    # and will flatten the sequence dimension into the batch.\n",
    "    data_log = sae.optimize_on_activations(\n",
    "        activations,\n",
    "        batch_size=batch_size,\n",
    "        steps=steps,\n",
    "        log_freq=log_freq,\n",
    "        lr=lr\n",
    "    )\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    # Print final statistics from the training log.\n",
    "    if data_log:\n",
    "        final_stats = data_log[-1]\n",
    "        print(\"\\nFinal training statistics:\")\n",
    "        for key, value in final_stats.items():\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/cdt_cw_5265_z_gwnxlf0tv80000gn/T/ipykernel_85085/1698669411.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  activations = torch.load(activation_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Step 0: lr=0.001000, loss=3014.034912, frac_active=0.419124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 48\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Train the model on the activations.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# The optimize_on_activations method expects a tensor of shape (N, seq_len, d_model)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# and will flatten the sequence dimension into the batch.\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m data_log \u001b[38;5;241m=\u001b[39m \u001b[43msae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_on_activations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Print final statistics from the training log.\u001b[39;00m\n",
      "File \u001b[0;32m~/sae-training/jumprelu_sae.py:405\u001b[0m, in \u001b[0;36mJumpReLUSAE.optimize_on_activations\u001b[0;34m(self, activations, batch_size, steps, log_freq, lr, lr_scale, resample_method, resample_freq, resample_window, resample_scale, hidden_sample_size)\u001b[0m\n\u001b[1;32m    402\u001b[0m     group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m step_lr\n\u001b[1;32m    404\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 405\u001b[0m total_loss, loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m total_loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    407\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/sae-training/jumprelu_sae.py:334\u001b[0m, in \u001b[0;36mJumpReLUSAE.compute_loss\u001b[0;34m(self, input_acts)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03mComputes the total loss: reconstruction + sparsity penalty.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m    loss_dict: Dictionary with individual loss components.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    333\u001b[0m acts, pre_acts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(input_acts)\n\u001b[0;32m--> 334\u001b[0m recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43macts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m L_reconstruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_reconstruction_loss(input_acts, recon)\n\u001b[1;32m    336\u001b[0m L_sparsity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_sparsity_loss(pre_acts)\n",
      "File \u001b[0;32m~/sae-training/jumprelu_sae.py:280\u001b[0m, in \u001b[0;36mJumpReLUSAE.decode\u001b[0;34m(self, acts)\u001b[0m\n\u001b[1;32m    277\u001b[0m     acts \u001b[38;5;241m=\u001b[39m relu_acts \u001b[38;5;241m*\u001b[39m mask\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acts, pre_acts\n\u001b[0;32m--> 280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, acts: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    281\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    Reconstructs the input from latent activations.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m        Reconstructed input of shape (..., d_model)\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acts \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_dec \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_dec\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
